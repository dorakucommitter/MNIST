{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNISTチュートリアルサイト\n",
    "* [TensorFlow MNIST For ML Beginners](https://www.tensorflow.org/tutorials)\n",
    "* [TensorFlowチュートリアル - ML初心者のためのMNIST（翻訳） - Qiita](http://qiita.com/KojiOhki/items/ff6ae04d6cf02f1b6edf)\n",
    "* [初心者必読！MNIST実行環境の準備から手書き文字識別までを徹底解説！ | 技術ブログ | MIYABI Lab](https://miyabi-lab.space/blog/10)\n",
    "\n",
    "## 考え方\n",
    "* [TensorFlowコトハジメ 手書き文字認識(MNIST)による多クラス識別問題](http://yaju3d.hatenablog.jp/entry/2016/04/22/073249)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通機能\n",
    "import time\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始時間のタイムスタンプ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始時刻\n",
    "start_time = time.time()\n",
    "print('開始時刻: %f' % start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像データの読込み\n",
    "* 訓練用画像 55000件 (60000件という説もあるらしい)\n",
    "* テスト用画像 10000件\n",
    "* 訓練データとテストデータは、それぞれ0～9の画像とそれぞれの画像に対応するラベル（0～9）が設定されている\n",
    "* 画像サイズは28px X 28px(=784)\n",
    "* mnist.train.imagesは[55000, 784]の配列\n",
    "* mnist.train.lablesは、read_data_setsメソッドのone_hotのT/Fにより下記の通り  \n",
    "    * one_hot = Trueの場合 : [55000, 10]の配列で、対応するimagesの画像が「3」の時、[0,0,0,1,0,0,0,0,0,0]\n",
    "    ```\n",
    "    np.argmax([0,0,0,1,0,0,0,0,0,0]) ⇒ 3に変換できる\n",
    "    ```\n",
    "    * one_hot = Falseの場合: [55000, 1]の配列で、対応するimagesの画像が「3」の時、3  \n",
    "* mnist.test.imagesは[10000, 784]の配列、mnist.test.lablesは[10000, 10]の配列で、内容はmnist.trainと同様\n",
    "* mnist.validation.imagesというデータも5,000件ほど存在するが、チュートリアルでは登場しない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- MNISTデータの読み込み開始 ---\")\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "print(\"--- MNISTデータの読み込み完了 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練画像、正解ラベル等のパラメータ定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練画像を入れる変数\n",
    "# 訓練画像は28x28pxであり、これらを1行784列の画素配列に並び替えて格納する\n",
    "# Noneとなっているのは、訓練画像をいくつ入れるか変数定義時点ではわからないため、\n",
    "# いくつでも格納できるようにするための手法\n",
    "# C言語でいうところのNULL Arrayみたいな感じ？\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# 正解データのラベル\n",
    "# 0～9までの数値は、数値ではなく10個の配列が代入される\n",
    "# ラベルの値=7の場合：  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 重み\n",
    "# 訓練画像のpx数の行、ラベル（0-9の数字の個数）数の列の行列\n",
    "# 初期値として0を入れておく\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "# バイアス\n",
    "# ラベル数の列の行列\n",
    "# 初期値として0を入れておく\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの作成\n",
    "\n",
    "## 大雑把な考え方\n",
    "mnist_beginnerでは、画素配列の１要素ごとに１次関数で0～9らしさのようなものを算出し、全体に占める割合が一番大きかったラベルを識別結果と判断します。なので、数式的には、\n",
    "\n",
    "    y = x * W + b\n",
    "      W: 重み(weight)\n",
    "      b: バイアス\n",
    "\n",
    "を画素の数だけ計算します。\n",
    "とりあえず、重みWで数字らしさを評価し、バイアスで数値ごとの総和を調整する、のように考えると、なんとなく納得できるような気がします。\n",
    "\n",
    "### バイアスを足す理由（推測）\n",
    "グレースケールで黒⇒白の色調を0⇒255の数値で表すため、認識結果が、白が多い数値ほど`x * W`が大きく、黒が多いほど`x * W`の値が小さくなり、数値そのものより画像全体に占める白黒の割合に左右されてしまいます（たぶん）。このため、バイアスを使って総和の調整をしている、と勝手に思っています。\n",
    "\n",
    "## ソフトマックス、交差エントロピー、勾配降下法\n",
    "* [損失関数）クロスエントロピー誤差](https://qiita.com/celaeno42/items/7efdbb1491406f4bde96)\n",
    "* [TensorFlowのクロスエントロピー関数の動作](https://qiita.com/exy81/items/8c9ab6ba8d4a03873d7c)\n",
    "* [ソフトマックス関数とシグモイド関数でのクロスエントロピー誤差関数について](http://lapislazuli.home.localnet:8888/notebooks/ipynb/mnist_beginners.ipynb)\n",
    "\n",
    "* 勾配降下法\n",
    "    * [勾配降下法ってなんだろう - 白猫のメモ帳](https://shironeko.hateblo.jp/entry/2016/10/29/173634)\n",
    "    * [2017-08-27\n",
    "ディープラーニング(深層学習)を理解してみる(勾配降下法：最急降下法と確率的勾配降下法)](http://yaju3d.hatenablog.jp/entry/2017/08/27/233459)\n",
    "    * [確率的勾配降下法とは何か、をPythonで動かして解説する](http://lapislazuli.home.localnet:8888/notebooks/ipynb/mnist_beginners.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス\n",
    "# yは入力x（画像）に対し、それがある数字である確率の配列\n",
    "# matmul関数で行列xとWの掛け算を行った後、bを加算する。\n",
    "# yは[1, 10]の行列\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 交差エントロピー\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "\n",
    "# 勾配降下法を用い交差エントロピーが最小となるようyを最適化する\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用意した変数Veriableの初期化を実行する\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Sessionを開始する\n",
    "# runすることで初めて実行開始される（run(init)しないとinitが実行されない）\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 1000回の訓練（train_step）を実行する\n",
    "# next_batch(100)で100つのランダムな訓練セット（画像と対応するラベル）を選択する\n",
    "# 訓練データは60000点あるので全て使いたいところだが費用つまり時間がかかるのでランダムな100つを使う\n",
    "# 100つでも同じような結果を得ることができる\n",
    "# feed_dictでplaceholderに値を入力することができる\n",
    "print(\"--- 訓練開始 ---\")\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_:batch_ys})\n",
    "print(\"--- 訓練終了 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 認識精度の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト画像がどの数字であるかの予測yと正解ラベルy_を比較する\n",
    "# 同じ値であればTrueが返される\n",
    "# argmaxは配列の中で一番値の大きい箇所のindexが返される\n",
    "# 一番値が大きいindexということは、それがその数字である確率が一番大きいということ\n",
    "# Trueが返ってくるということは訓練した結果と回答が同じということ\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "# 精度の計算\n",
    "# correct_predictionはbooleanなのでfloatにキャストし、平均値を計算する\n",
    "# Trueならば1、Falseならば0に変換される\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# 精度の実行と表示\n",
    "# テストデータの画像とラベルで精度を確認する\n",
    "# ソフトマックス回帰によってWとbの値が計算されているので、xを入力することでyが計算できる\n",
    "print(\"精度\")\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 終了時刻\n",
    "end_time = time.time()\n",
    "print(\"終了時刻: \" + str(end_time))\n",
    "print(\"かかった時間: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# このスクリプトが獲得した成果物の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バイアスb配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = sess.run(b)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重みW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像認識結果の描画\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "# Weightの値\n",
    "weights = sess.run(W)\n",
    "\n",
    "fig, axarr = plt.subplots(2, 5)\n",
    "for idx in range(10):\n",
    "    ax = axarr[int(idx / 5)][idx % 5]\n",
    "    ax.imshow(weights[:, idx].reshape(28, 28), cmap = cm.Greys_r)\n",
    "    ax.set_title(str(idx))\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
