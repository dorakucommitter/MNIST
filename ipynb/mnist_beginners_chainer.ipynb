{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "\n",
    "ChainerのMNISTのチュートリアルではいきなり3層モデルで実装しているので、ここでは最も単純な1層モデルを実装します。  \n",
    "1層モデルは、機械学習の成果物（WeightとBias）が確認しやすいメリットがあります。  \n",
    "ただ、Chainerだと、\n",
    "\n",
    "    y = Wx + b\n",
    "\n",
    "の数式がイメージしにくいです。\n",
    "\n",
    "\n",
    "# 参考サイト\n",
    "\n",
    "- [Chainer v4 ビギナー向けチュートリアル](https://qiita.com/mitmul/items/1e35fba085eb07a92560)\n",
    "- [chainer/examples/mnist at master · chainer/chainer · GitHub](https://github.com/chainer/chainer/tree/master/examples/mnist)\n",
    "- [ChainerでMNISTの手書き文字認識 - しがないエンジニアのブログ](http://turgure.hatenablog.com/entry/2016/08/04/010219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 共通ライブラリ\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# 画像表示\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNISTデータの取得\n",
    "\n",
    "[get_mnist関数](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.get_mnist.html) を使って、Chainerで用意しているMNISTデータセット（70,000件）を取得し、下記のように分割する。\n",
    "\n",
    "* 訓練データ： 50,000件\n",
    "* 検証データ： 10,000件\n",
    "* テストデータ： 10,000件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import mnist, split_dataset_random\n",
    "\n",
    "### データセットを取得する。すでに取得済みの場合、取得済みデータセットをロードする。\n",
    "# withlabel=True： 画像データと画像データに対応する数値をタプル形式で取得する\n",
    "# ndim： 取得する画素配列の次元を指定する。\n",
    "#    ndim=1： 784 x 1の１次元配列\n",
    "#    ndim=2： 28 x 28の２次元配列\n",
    "#    ndim=3：　色 x 28 x 28の３次元配列\n",
    "#\n",
    "train_val, test_data = mnist.get_mnist(withlabel=True, ndim=1)\n",
    "train_data, valid_data = split_dataset_random(train_val, 50000, seed=0)\n",
    "#print(train_data)\n",
    "#print(valid_data)\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練画像先頭10枚の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training dataset size:', len(train_data))\n",
    "# 訓練画像先頭10枚の確認\n",
    "# 2行x5列の画像出力領域を確保\n",
    "fig, axarr = plt.subplots(2, 5)\n",
    "# 各出力領域に絵をセットする\n",
    "for idx in range(10):\n",
    "    ax = axarr[int(idx / 5)][idx % 5]\n",
    "\n",
    "    x, t = train_data[idx] \n",
    "    ax.imshow(x.reshape(28, 28), cmap = cm.Greys_r)\n",
    "    ax.set_title(str(t))\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "# 絵を出力する\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証画像先頭10枚の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation dataset size:', len(valid_data))\n",
    "# validate画像先頭10枚の確認\n",
    "# 2行x5列の画像出力領域を確保\n",
    "fig, axarr = plt.subplots(2, 5)\n",
    "# 各出力領域に絵をセットする\n",
    "for idx in range(10):\n",
    "    ax = axarr[int(idx / 5)][idx % 5]\n",
    "\n",
    "    x, t = valid_data[idx] \n",
    "    ax.imshow(x.reshape(28, 28), cmap = cm.Greys_r)\n",
    "    ax.set_title(str(t))\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "# 絵を出力する\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト画像先頭10枚の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test dataset size:', len(valid_data))\n",
    "# テスト画像先頭10枚の確認\n",
    "# 2行x5列の画像出力領域を確保\n",
    "fig, axarr = plt.subplots(2, 5)\n",
    "# 各出力領域に絵をセットする\n",
    "for idx in range(10):\n",
    "    ax = axarr[int(idx / 5)][idx % 5]\n",
    "\n",
    "    x, t = test_data[idx] \n",
    "    ax.imshow(x.reshape(28, 28), cmap = cm.Greys_r)\n",
    "    ax.set_title(str(t))\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "# 絵を出力する\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteratorの作成\n",
    "\n",
    "ネットワークのパラメータ最適化手法として広く用いられるStochastic Gradient Descent(SGD)という手法では、いくつかのデータを束ねたミニバッチと呼ばれる単位ごとに推論→パラメータ更新を行い、全ミニバッチについて推論→パラメータ更新が完了したことを１epochという単位として、推論時の予測精度が収束するまでepochを繰り返します。  \n",
    "Chainerで学習データとそのラベルを束ね、ミニバッチに相当するデータセットを作成する機能をIteratorと呼び、ここで使用する[SerialIterator以外にもいくつかのIterator](https://docs.chainer.org/en/stable/reference/iterators.html)が用意されています。\n",
    "\n",
    "*  [オンライン学習、バッチ学習、ミニバッチ学習の違い](https://ja.stackoverflow.com/questions/48021/%e3%82%aa%e3%83%b3%e3%83%a9%e3%82%a4%e3%83%b3%e5%ad%a6%e7%bf%92-%e3%83%90%e3%83%83%e3%83%81%e5%ad%a6%e7%bf%92-%e3%83%9f%e3%83%8b%e3%83%90%e3%83%83%e3%83%81%e5%ad%a6%e7%bf%92%e3%81%ae%e9%81%95%e3%81%84ß)\n",
    "* [畳み込みニューラルネ​ットワークの学習にお​けるミニバッチの精度​とは何ですか？](https://jp.mathworks.com/matlabcentral/answers/333915-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import iterators\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "# ここでは１２８個のデータを一括りにして、推論→パラメータ更新を行う\n",
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train_data, batchsize)\n",
    "valid_iter = iterators.SerialIterator(valid_data, batchsize, repeat=False, shuffle=False)\n",
    "test_iter = iterators.SerialIterator(test_data, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワーク定義\n",
    "\n",
    "ここでは中間層なしで、入力画像を0〜9の１０クラスに分類するネットワークを作成します。\n",
    "学習のイメージとしては、下記の数式に対し、各画素配列要素ごとにyを計算し、ラベルと同じかどうかをチェックして、違った場合は同じになるようにW、bを調整していく感じです。  \n",
    "ちなみに、Wとbの初期値は乱数です（0でも良いらしいのですが、乱数の方が学習速度が早いらしいです）。\n",
    "\n",
    "    y = Wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークモデル\n",
    "# 入力784, 出力10, 単層\n",
    "class MnistBeginner(Chain):\n",
    "    def __init__(self):\n",
    "        super(MnistBeginner, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # 第1引数が入力画素配列。784としてしても結果は同じになる。\n",
    "            self.l1 = L.Linear(None, 10)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.l1(x)\n",
    "    \n",
    "    def getWeight(self):\n",
    "        return self.l1.W\n",
    "\n",
    "    def getBias(self):\n",
    "        return self.l1.b\n",
    "\n",
    "net = MnistBeginner()\n",
    "\n",
    "gpu_id = -1  # CPUを用いる場合は、この値を-1にしてください\n",
    "if gpu_id >= 0:\n",
    "    net.to_gpu(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法\n",
    "\n",
    "* [Chainerで使える最適化手法](https://docs.chainer.org/en/stable/reference/optimizers.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import optimizers\n",
    "optimizer = optimizers.SGD(lr=0.01).setup(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.dataset import concat_examples\n",
    "from chainer.cuda import to_cpu\n",
    "\n",
    "max_epoch = 20\n",
    "\n",
    "while train_iter.epoch < max_epoch:\n",
    "\n",
    "    # ---------- 学習の1イテレーション ----------\n",
    "    train_batch = train_iter.next()\n",
    "    x, t = concat_examples(train_batch, gpu_id)\n",
    "\n",
    "    # 予測値の計算\n",
    "    y = net(x)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    # 勾配の計算\n",
    "    net.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    optimizer.update()\n",
    "    # --------------- ここまで ----------------\n",
    "\n",
    "    # 1エポック終了ごとにValidationデータに対する予測精度を測って、\n",
    "    # モデルの汎化性能が向上していることをチェックしよう\n",
    "    if train_iter.is_new_epoch:  # 1 epochが終わったら\n",
    "\n",
    "        # ロスの表示\n",
    "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
    "            train_iter.epoch, float(to_cpu(loss.data))), end='')\n",
    "\n",
    "        valid_losses = []\n",
    "        valid_accuracies = []\n",
    "        while True:\n",
    "            valid_batch = valid_iter.next()\n",
    "            x_valid, t_valid = concat_examples(valid_batch, gpu_id)\n",
    "\n",
    "            # Validationデータをforward\n",
    "            with chainer.using_config('train', False), \\\n",
    "                    chainer.using_config('enable_backprop', False):\n",
    "                y_valid = net(x_valid)\n",
    "\n",
    "            # ロスを計算\n",
    "            loss_valid = F.softmax_cross_entropy(y_valid, t_valid)\n",
    "            valid_losses.append(to_cpu(loss_valid.array))\n",
    "\n",
    "            # 精度を計算\n",
    "            accuracy = F.accuracy(y_valid, t_valid)\n",
    "            accuracy.to_cpu()\n",
    "            valid_accuracies.append(accuracy.array)\n",
    "\n",
    "            if valid_iter.is_new_epoch:\n",
    "                valid_iter.reset()\n",
    "                break\n",
    "\n",
    "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
    "            np.mean(valid_losses), np.mean(valid_accuracies)))\n",
    "\n",
    "# テストデータでの評価\n",
    "test_accuracies = []\n",
    "while True:\n",
    "    test_batch = test_iter.next()\n",
    "    x_test, t_test = concat_examples(test_batch, gpu_id)\n",
    "\n",
    "    # テストデータをforward\n",
    "    with chainer.using_config('train', False), \\\n",
    "            chainer.using_config('enable_backprop', False):\n",
    "        y_test = net(x_test)\n",
    "\n",
    "    # 精度を計算\n",
    "    accuracy = F.accuracy(y_test, t_test)\n",
    "    accuracy.to_cpu()\n",
    "    test_accuracies.append(accuracy.array)\n",
    "\n",
    "    if test_iter.is_new_epoch:\n",
    "        test_iter.reset()\n",
    "        break\n",
    "\n",
    "print('test_accuracy:{:.04f}'.format(np.mean(test_accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weightの内容\n",
    "\n",
    "chainerの変数はVariableクラスになっていて、arrayプロパティにnumpy配列が格納されているらしい。\n",
    "\n",
    "* [chainer.Variable - chainerfan ページ！](https://chainerfan.jimdo.com/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%83%AA%E3%82%B9%E3%83%881/chainer-variable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = net.getWeight()\n",
    "print(weights.shape)\n",
    "\n",
    "fig, axarr = plt.subplots(2, 5)\n",
    "for idx in range(10):\n",
    "    ax = axarr[int(idx / 5)][idx % 5]\n",
    "    img_src = (weights[idx, :].array * 100).astype(np.int32)\n",
    "\n",
    "    #print((weights[idx, :].array * 100).astype(np.int32))\n",
    "    ax.imshow(img_src.reshape(28, 28), cmap = cm.Greys_r)\n",
    "    ax.set_title(str(idx))\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バイアスの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = net.getBias()\n",
    "print(bias.array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
